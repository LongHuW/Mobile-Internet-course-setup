{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####将特征文件训练集测试集切割,分割是手动的，该模块仅用于获取各个label的标签index,因为已经知道顺序是1302\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "params = {}\n",
    "###特征提取方法\n",
    "params['feature_path']=r'E:\\文件夹\\大三下\\移动互联网课设\\大作业\\CWRU0319\\feature\\time_fre'\n",
    "params['data_path'] = params['feature_path']+'.csv'\n",
    "test = np.array(pd.read_csv(params['data_path'],keep_default_na=False))##后面这个参数可以解决空值带来的问题\n",
    "test_x = test[:, :-1]\n",
    "test_y=test[:,-1]#获取文件标签\n",
    "every_file_number=np.zeros(4)#计数每一个测试文件的特征数量数组\n",
    "#获得每个测试文件的特征数量\n",
    "for file_label in test_y:\n",
    "    every_file_number[int(file_label)]+=1\n",
    "###按7：3切割，算一下，因为有小数等原因，肯定会有1，2条数据的差错，但没什么大影响\n",
    "a=np.zeros(8)\n",
    "a[0]=every_file_number[1]*0.7\n",
    "a[1]=every_file_number[1]\n",
    "a[2]=every_file_number[1]*0.7+every_file_number[3]*0.7\n",
    "a[3]=every_file_number[1]*0.7+every_file_number[3]\n",
    "a[4]=every_file_number[1]*0.7+every_file_number[3]*0.7+every_file_number[0]*0.7\n",
    "a[5]=every_file_number[1]*0.7+every_file_number[3]*0.7+every_file_number[0]\n",
    "a[6]=every_file_number[1]*0.7+every_file_number[3]*0.7+every_file_number[0]*0.7+every_file_number[2]*0.7\n",
    "a[7]=every_file_number[1]*0.7+every_file_number[3]*0.7+every_file_number[0]*0.7+every_file_number[2]\n",
    "#最终训练集标签值\n",
    "print(a)\n",
    "#测试集标签值\n",
    "b=np.zeros(8)\n",
    "b[0]=0\n",
    "b[1]=every_file_number[1]*0.7\n",
    "b[2]=every_file_number[1]*0.3\n",
    "b[3]=every_file_number[1]*0.3+every_file_number[3]*0.7\n",
    "b[4]=every_file_number[1]*0.3+every_file_number[3]*0.3\n",
    "b[5]=every_file_number[1]*0.3+every_file_number[3]*0.3+every_file_number[0]*0.7\n",
    "b[6]=every_file_number[1]*0.3+every_file_number[3]*0.3+every_file_number[0]*0.3\n",
    "b[7]=every_file_number[1]*0.3+every_file_number[3]*0.3+every_file_number[0]*0.3+every_file_number[2]*0.7\n",
    "#最终训练集标签值\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###获取训练集测试集数据\n",
    "params['train_data_path'] = params['feature_path']+'_train.csv'\n",
    "train = np.array(pd.read_csv(params['train_data_path'],keep_default_na=False))##后面这个参数可以解决空值带来的问题\n",
    "train_x = train[:, :-1]\n",
    "train_y= train[:,-1]#获取文件标签\n",
    "params['test_data_path'] =params['feature_path']+'_test.csv'\n",
    "test = np.array(pd.read_csv(params['test_data_path'],keep_default_na=False))##后面这个参数可以解决空值带来的问题\n",
    "test_x = test[:, :-1]\n",
    "test_y=test[:,-1]#获取文件标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF模型优化\n",
    "###通过不断迭代优化模型参数\n",
    "###如果有的参数处于边界值，最好更改边界值在来一次，虽然即使没在边界值，也可能最优解在取值范围外\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# #有batime经过三次调参0.97\n",
    "# params['n_estimators'] = 100\n",
    "# params['max_depth'] = 11\n",
    "# params['max_features'] = 3\n",
    "# params['min_samples_split'] = 70\n",
    "# params['min_samples_leaf'] = 10\n",
    "#无batime\n",
    "params['n_estimators']=70\n",
    "params['max_depth']=13\n",
    "params['min_samples_split']=70\n",
    "params['min_samples_leaf']=1\n",
    "params['max_features']=3\n",
    "q1=params['n_estimators']\n",
    "q2=params['max_depth']\n",
    "q3=params['min_samples_split']\n",
    "q4=params['min_samples_leaf']\n",
    "q5=params['max_features']\n",
    "def RF_n_estimators(params,train_x, train_y):\n",
    "    param_test = {'n_estimators': range(10, 101, 10)}\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(\n",
    "                    min_samples_split=params['min_samples_split'],\n",
    "                    min_samples_leaf=params['min_samples_leaf'],\n",
    "                    max_depth=params['max_depth'],\n",
    "                    max_features=params['max_features'],\n",
    "                    random_state=10,\n",
    "                    ),\n",
    "        param_grid=param_test,\n",
    "        scoring='accuracy',\n",
    "        cv=5)\n",
    "    gsearch.fit(train_x, train_y)\n",
    "    return gsearch.best_params_.get('n_estimators')\n",
    "\n",
    "def RF_max_depth_min_samples_split(params,train_x, train_y):\n",
    "    param_test = {'max_depth': range(3, 24, 2), 'min_samples_split': range(50, 201, 20)}\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_features=params['max_features'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "            oob_score=True,\n",
    "            random_state=10),\n",
    "        param_grid=param_test,\n",
    "        scoring='accuracy',\n",
    "        iid=False,\n",
    "        cv=5)\n",
    "    gsearch.fit(train_x, train_y)\n",
    "    return gsearch.best_params_.get('max_depth'),gsearch.best_params_.get('min_samples_split')\n",
    "\n",
    "def RF_min_samples_split_min_samples_leaf(params,train_x, train_y):\n",
    "    param_test = {'min_samples_split': range(params['min_samples_split'], 200, 20), 'min_samples_leaf': range(1, 10, 1)}\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            max_features=params['max_features'],\n",
    "            oob_score=True,\n",
    "            random_state=10),\n",
    "        param_grid=param_test,\n",
    "        scoring='accuracy',\n",
    "        iid=False,\n",
    "        cv=5)\n",
    "    gsearch.fit(train_x, train_y)\n",
    "    return gsearch.best_params_.get('min_samples_split'),gsearch.best_params_.get('min_samples_leaf')\n",
    "\n",
    "def RF_max_features(params,train_x, train_y):\n",
    "    param_test = {'max_features': range(1, 10, 1)}\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "                    random_state=10,\n",
    "                    ),\n",
    "        param_grid=param_test,\n",
    "        scoring='accuracy',\n",
    "        cv=5)\n",
    "    gsearch.fit(train_x, train_y)\n",
    "    return gsearch.best_params_.get('max_features')\n",
    "#迭代次数\n",
    "i=np.zeros(5)\n",
    "while 1<2:\n",
    "    ###归0\n",
    "    q11=0\n",
    "    q22=0\n",
    "    q33=0\n",
    "    q44=0\n",
    "    q55=0\n",
    "    params['n_estimators'] = RF_n_estimators(params,train_x, train_y)\n",
    "    if params['n_estimators']!=q1:\n",
    "        i[0]+=1\n",
    "        print(\"n_estimators迭代次数:\"+str(i[0]))\n",
    "        q1=params['n_estimators']\n",
    "        q11=1\n",
    "    params['max_depth'],params['min_samples_split'] = RF_max_depth_min_samples_split(params,train_x, train_y)\n",
    "    if params['max_depth']!=q2:\n",
    "        i[1]+=1\n",
    "        print(\"max_depth迭代次数:\"+str(i[1]))\n",
    "        q2=params['max_depth']\n",
    "        q22=1    \n",
    "    params['min_samples_split'],params['min_samples_leaf'] = RF_min_samples_split_min_samples_leaf(params,train_x, train_y)\n",
    "    if params['min_samples_split']!=q3:\n",
    "        i[2]+=1\n",
    "        print(\"'min_samples_split:\"+str(i[2]))\n",
    "        q3=params['min_samples_split']\n",
    "        q33=1  \n",
    "    if params['min_samples_leaf']!=q4:\n",
    "        i[3]+=1\n",
    "        print(\"min_samples_leaf迭代次数:\"+str(i[3]))\n",
    "        q4=params['min_samples_leaf']\n",
    "        q44=1  \n",
    "    params['max_features'] = RF_max_features(params,train_x, train_y)\n",
    "    if params['max_features']!=q5:\n",
    "        i[4]+=1\n",
    "        print(\"max_features迭代次数:\"+str(i[4]))\n",
    "        q5=params['max_features']\n",
    "        q55=1  \n",
    "    if q11==0 and q22==0 and q33==0 and q44==0 and q55==0:\n",
    "        ###即所有参数已经不再变化,则不在优化\n",
    "        break\n",
    "print(\"params['n_estimators']=\"+str(params['n_estimators']))\n",
    "print(\"params['max_depth']=\"+str(params['max_depth']))\n",
    "print(\"params['min_samples_split']=\"+str(params['min_samples_split']))\n",
    "print(\"params['min_samples_leaf']=\"+str(params['min_samples_leaf']))\n",
    "print(\"params['max_features']=\"+str(params['max_features']))\n",
    "\n",
    "##模型评估\n",
    "rf = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        max_features=params['max_features'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        oob_score=True,\n",
    "        random_state=10\n",
    "        )\n",
    "rf.fit(train_x, train_y)\n",
    "y_pred = rf.predict(test_x)\n",
    "# 模型评价\n",
    "f1 = f1_score(test_y, y_pred, average='macro')\n",
    "acc = accuracy_score(test_y, y_pred)\n",
    "print('f1 : ', f1)\n",
    "print('accuracy : ', acc)\n",
    "\n",
    "# ##result0.7:0.3\n",
    "# params['n_estimators']=20\n",
    "# params['max_depth']=11\n",
    "# params['min_samples_split']=210\n",
    "# params['min_samples_leaf']=3\n",
    "# params['max_features']=3\n",
    "# # f1 :  0.6928239891855987\n",
    "# # accuracy :  0.9608948087431693\n",
    "# ###result1.0来得到参数，在0.7：0.3来训练测试\n",
    "# params['n_estimators']=70\n",
    "# params['max_depth']=13\n",
    "# params['min_samples_split']=70\n",
    "# params['min_samples_leaf']=1\n",
    "# params['max_features']=3\n",
    "# # f1 :  0.8010062215899816\n",
    "# # accuracy :  0.9748975409836066"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
