{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "params={}\n",
    "params['data_path']=r'E:\\文件夹\\大三下\\移动互联网课设\\大作业\\训练\\feature\\time+fre.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data=pd.read_csv(params['data_path'],keep_default_na=False)##后面这个参数可以解决空值带来的问题\n",
    "data = np.array(re_data)\n",
    "data_x = data[:, :-1]\n",
    "data_y=data[:,-1]#获取文件标签\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(  \n",
    "    data_x,  \n",
    "    data_y,  \n",
    "    test_size=0.1,  \n",
    "    random_state=2020\n",
    ")  \n",
    "\n",
    "def modelfit(params , alg ,X_train , X_test, y_train, y_test,early_stopping_rounds=10):\n",
    "    lgbm_params = params.copy()\n",
    "    lgbm_params['num_class'] = 4\n",
    "    lgbm_params.pop('silent');\n",
    "     \n",
    "    lgbmtrain = lgbm.Dataset(X_train , y_train , silent=True)\n",
    "     \n",
    "    #num_boost_round为弱分类器数目，下面的代码参数里因为已经设置了early_stopping_rounds\n",
    "    #即性能未提升的次数超过过早停止设置的数值，则停止训练\n",
    "    cv_result = lgbm.cv(lgbm_params , lgbmtrain , num_boost_round=10000 , nfold=5 , stratified=True , shuffle=True , metrics='multi_logloss' , early_stopping_rounds=early_stopping_rounds , show_stdv=True , seed=0 )\n",
    "     \n",
    "    print('best n_estimators:' , len(cv_result['multi_logloss-mean']))\n",
    "    print('best cv score:' , cv_result['multi_logloss-mean'][-1])\n",
    "     \n",
    "    #采用交叉验证得到的最佳参数n_estimators,训练模型\n",
    "    alg.set_params(n_estimators=len(cv_result['multi_logloss-mean']))\n",
    "    alg.fit(X_train , y_train)\n",
    "    \n",
    "    y_pred = alg.predict(X_test)\n",
    "    # 模型评价\n",
    "    f1 = f1_score( y_test, y_pred, average='macro')\n",
    "    acc = accuracy_score( y_test, y_pred)\n",
    "    print('f1 : ', f1)\n",
    "    print('accuracy : ', acc)\n",
    "    \n",
    "params = {'boosting_type': 'gbdt',\n",
    "      'objective': 'multiclass',\n",
    "      'nthread': -1,\n",
    "      'silent': True,#是否打印信息，默认False\n",
    "      'learning_rate': 0.1,\n",
    "      'num_leaves': 80,\n",
    "      'max_depth': 5,\n",
    "      'max_bin': 127,\n",
    "      'subsample_for_bin': 50000,\n",
    "      'subsample': 0.8,\n",
    "      'subsample_freq': 1,\n",
    "      'colsample_bytree': 0.8,\n",
    "      'reg_alpha': 1,\n",
    "      'reg_lambda': 0,\n",
    "      'min_split_gain': 0.0,\n",
    "      'min_child_weight': 1,\n",
    "      'min_child_samples': 20,\n",
    "      'scale_pos_weight': 1}\n",
    " \n",
    "lgbm1 = lgbm.sklearn.LGBMClassifier(num_class=4 , n_estimators=1000 , seed=0 , **params)\n",
    " \n",
    "modelfit(params , lgbm1 ,X_train , X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
